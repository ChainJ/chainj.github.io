{"./":{"url":"./","title":"Introduction","keywords":"","body":"Head of MimirHead of Mimir The smartest head in the world! var gitalk = new Gitalk({ clientID: '6c5979cef62fdd9b4854', clientSecret: 'af796559c2892e1ebbf10480d8c2fc2d0bb4af24', repo: 'chainj.github.io', owner: 'ChainJ', admin: ['ChainJ'], id: location.pathname, distractionFreeMode: false }) gitalk.render('gitalk-container') © Cheng all right reserved，powered by GitbookModified At: 2021-12-10 14:22:34 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"programming/":{"url":"programming/","title":"Programming","keywords":"","body":"ProgrammingProgramming Java Java-Base-1 Spring-Base-1 © Cheng all right reserved，powered by GitbookModified At: 2021-06-21 20:49:51 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"programming/java/":{"url":"programming/java/","title":"Java","keywords":"","body":"JavaHello JavaJava Hello Java © Cheng all right reserved，powered by GitbookModified At: 2021-06-21 20:43:46 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"programming/java/java-base-1/page.html":{"url":"programming/java/java-base-1/page.html","title":"Java Base 1","keywords":"","body":"Java 编程基础JDK、JRE和JavaSEJVMJMM多线程编程GCObject类常用开发工具类Lambda表达式和Stream API接口、注解、反射、范型MavenJava 编程基础 这是一篇面向Ruby语言编程者的培训文档，主要介绍Java语言的基本概念和编程技巧。 JDK、JRE和JavaSE JRE(Java Runtime Environment)，Java运行环境，与Ruby Core类似，主要提供Java核心类库和JVM。由于只是运行环境，JRE不可用于源代码编译。 JDK(Java Development Kit)，Java开发者工具，除核心类库外，还提供编译、运行、调试等工具。JDK9及以前的版本中，jre不再作为一个独立文件存 在jdk目录下。下载IDEA会自带openJDK，但有个缺陷是没有Javadoc，所以我还是建议自行去Oracle官网下载JDK，可以很方便查看各类接口的文档和设计说明。 JavaSE(Java Standard Edition)，Oracle提供的标准版JDK，与前文提及的JDK比，缺少JavaFX、Swing、WebService等桌面编程和Web应用类库。 但桌面应用时代已过去，JSP等技术也成为历史垃圾，所这些存在于JavaEE(Java Enterprise Edition)的库对互联网时代的微服务开发没有什么帮助 JVM JVM(Java Virtual Machine)，Java语言跨平台运行的依赖，所有源码通过 javac 编译后，形成的字节码文件通过JVM调用操作系统资源。JVM是一种规范， 基于此规范有不同实现，主要的实现有HotSpot，基于硬件和实现算法的趋同，JRE8以后，HotSpot已经只提供一种实现，即Server VM。Scala、Groovy、 Kotlin等编译后的字节码能被JVM识别的语言都可以借助JVM运行，甚至实现与Java语言的互调。 日常编程中，与JVM相关比较重要的点有内存模型JMM(Java Memory Model)和GC(Garbage Collection)。 JMM 简单地说，Java的内存分为两部分，线程独有的栈和线程共享的堆，栈内的对象占用的内存随线程结束而释放，堆中的内存依赖于垃圾回收。细分下来，栈主要由 虚拟机栈(随线程创建)、本地方法栈、程序计数器组成；堆分为新生代、老年代、永久代(即方法区，存储加载的类基本信息和常量，JRE8以上的实现已经以MetaSpace替 代永久代PerGen，主要是引入操作系统内存代替固定分配的JVM内存来保存加载信息，实现内存动态分配)、运行时常量池(保存-128到127的整数，直接声明或调用了 String.intern函数的字符串等)。 Java的多线程模型与Ruby不同，可以利用多核cpu实现并发，所以内存模型和线程安全问题也更重要。在Ruby中，全局锁GIL机制保证了在常见的编码场景，如单 一函数内、非I/O场景下，类的实例对象和全局对象的线程安全，这使得Ruby编码过程中，大部分情况不用考虑有状态(stateful)类的线程安全问题。但Java中不 一样，当任意两个线程运行同一段代码时，Java没有默认的机制去保证线程安全(原子性、有序性、可见性)。对于有序性，Java只有一个简单的happens-before原则： 程序顺序规则：一个线程中的每个操作，逻辑上happens-before于该线程中的任意后续操作。 监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。 volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。 传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。 start()规则：线程的start操作happens-before于线程中的任意操作。 join()规则：线程中的任意操作happens-before于其他线程的join操作成功返回。 程序中断规则：对线程interrupted()方法的调用先行于被中断线程的代码检测到中断时间的发生。 对象finalize规则：一个对象的初始化完成（构造函数执行结束）先行于发生它的finalize()方法的开始。 多线程编程 基于内存模型，在Java编码过程中，涉及有状态类的处理，也需要时刻注意这个原则。常用处理方式有四种： 用volatile修饰类属性，volatile关键字通过内存屏障，保障修饰对象的可见性和有序性，所以此方式仅适用于原子性操作(如赋值运算，而++、+=不具有原子性) 用synchronized关键字修饰相关代码块，synchronized关键字通过对象的monitor锁，保障修饰目标的原子性、可见性和有序性，避免编译过程中的重排序。 如果锁住类的Class对象，可以锁住类的所有实例 借助JUC(java.util.concurrent包)框架下的Lock组件，如ReentrantLock、ReadWriteLock等实现类，或自行实现一个Lock实例，可以借助 AQS(AbstractQueuedSynchronizer)类 借助ThreadLocal类保存需要并发修改的对象，这些对象会与当前线程绑定，也可以用于跨对象传值 如果只是处理一些简单并发问题，如并发计数等，可以借助JUC框架一些工具类，如AtomicInteger、ConcurrentHashMap等。 多线程的实现方式有很多，简单的异步场景可以通过三种方式实现： 继承Thread类，并重写run方法。Java内的线程都是基于Thread类创建的，但Java遵循单继承、多实现的设计，所以这是一种既不优雅，也不便捷的实现方式。 大部分业务场景下，不推荐使用，除非实现依赖许多线程相关操作时，可以采用这个方法。 实现Runnable接口。Runnable接口只有一个run函数，会在线程启动后执行，在不需要得知线程执行结果的情况下可以使用这个方式。 实现Callable接口。Callable接口提供一个范型参数和一个call函数，call函数执行完成时，需要指定一个范型参数类型的返回值，这个值可以通过 Future接口获取，适合需要获取线程执行结果的场景 public class MultiThread { static long threadId(){ return Thread.currentThread().getId(); } static void sleep(long millis){ try { Thread.sleep(millis); } catch (InterruptedException e) { e.printStackTrace(); } } static class ThreadA extends Thread{ @Override public void run(){ System.out.println(\"ThreadA-\" + getId() + \" is running!\"); MultiThread.sleep(1000); System.out.println(\"ThreadA-\" + threadId() + \" has stopped!\"); } } static class RunnerA implements Runnable{ @Override public void run() { System.out.println(\"RunnerA-\" + threadId() + \" is running!\"); sleep(1000); System.out.println(\"RunnerA-\" + threadId() + \" has stopped!\"); } } static class CallerA implements Callable{ @Override public Integer call() throws Exception { System.out.println(\"CallerA-\" + threadId() + \" is running!\"); sleep(1000); System.out.println(\"CallerA-\" + threadId() + \" has returned!\"); return 666; } } public static void main(String... args){ // 继承方式实现多线程 ThreadA threadA = new ThreadA(); threadA.start(); // 实现Runnable接口 RunnerA runnerA = new RunnerA(); new Thread(runnerA).start(); // 实现Callable接口，需要配合FutureTask或ExecutorService框架实现 CallerA callerA = new CallerA(); FutureTask task = new FutureTask<>(callerA); new Thread(task).start(); try { System.out.println(\"task returns \" + task.get()); } catch (Exception e) { e.printStackTrace(); } } } 在稍微复杂一点的场景下，例如线程需要重复利用，或者需要获取多个线程结果，可以使用JUC的框架 ExecutorService，它是常用线程池模型 ThreadPoolExecutor的接口，Spring等框架也基于此接口提供许多实现。 public class Main { public static void main(String... args) throws Exception { ExecutorService threadPool = Executors.newFixedThreadPool(10); VolatileCounter counter = new VolatileCounter(0); List counters = new ArrayList<>(1000); for (int i = 0; i > futures = threadPool.invokeAll(counters); futures.forEach(o -> { try { System.out.print(o.get() + \" \"); } catch (Exception e) { e.printStackTrace(); } }); long end = System.currentTimeMillis(); System.out.println(\"\\ntask time cost: \" + (end - start) + \"ms\"); threadPool.shutdown(); System.out.println(\"counter: \" + counter.counter); } static class VolatileCounter implements Callable { volatile int counter = 0; VolatileCounter(int counter) { this.counter = counter; } @Override public Integer call() { try { Thread.sleep(50); } catch (InterruptedException e) { e.printStackTrace(); } return ++counter; } } } 利用Executors构造了一个10个核心线程的线程池，每个线程执行暂停50ms，1000个线程顺序执行需要50000ms，而结果显示任务结束仅耗时5258ms，说明10 个线程的并发度确实达到了。从程序结果中我们可以印证volatile关键字无法保证原子性。 这里有个细节是，运行程序的硬件是8核cpu，在超线程技术下，可以算作最多16个线程并行执行。理论上，线程池核心线程超过16后，任务运行耗时是不会再下降的， 也就是至少耗时3125ms，加上线程初始化、上下文切换和代码运行时间，耗时会更多。但实际情况是，我们把线程池核心线程数调整为1000的话，任务耗时会下降 到170ms，不是理论值3125ms，也不是设置的线程睡眠时间50ms。这是因为Thread.sleep()函数在调用时，会让出cpu时间片，交给其他线程使用，线程 状态进入TIMED_WAITING，该线程在等待时间内，不会再竞争cpu，所以这1000个核心线程不受16个cpu限制，可以看作在并行执行。而之所以耗时在170ms而不 是50ms，是因为cpu调度过程中，线程上下文切换的耗时无法避免。如果我们将上面代码中的call函数使用synchronized关键字修饰起来，无论核心线程数多大， 耗时都会是50000ms，因为synchronized关键字会使得当前执行线程持有对象的monitor锁，而Thread.sleep()函数只让出cpu时间片，却不会释放线程持有的锁。 public synchronized Integer call() { try { Thread.sleep(50); } catch (InterruptedException e) { e.printStackTrace(); } return ++counter; } 这个结果也侧面印证synchronized关键字保证修饰对象的原子性。 GC 垃圾回收是许多高级语言的特性，对于Java而言，垃圾回收主要作用于JMM堆区中的新生代(Young Generation)和老年代(Old Generation)，主要通过根搜索 算法和标记计数算法对不再使用的对象进行清除，并对内存空间进行压缩，减少内存碎片。而MetaSpace(旧称方法区/永久代，也包括常量池)因为自身特性，垃圾回 收主要面向无引用的常量，以及对已无任何实例或类加载器已被卸载的Class类信息进行卸载，第二个特性可用于一些动态字节码生成的场景，卸载动态类占用的内存。 对具体的GC算法不进行展开，我们只需要关心一下GC在实际编程中可能出现的应用。 首先需要了解三个概念，逃逸分析、栈上分配和TLAB： 逃逸分析：一种计算引用作用域的算法，通过连通图和引用可达性分析，在创建对象前，判断对象为全局逃逸、参数逃逸和不会逃逸三种状态，不会逃逸的对象可以 直接进行栈上分配。逃逸分析将对这类对象进行标量替换(将基本类型和Reference直接分配在栈帧或cpu的寄存器内，提高访问效率)和同步消除(创建对象时不需要获取同步锁)。 栈上分配：顾名思义，直接使用栈内存创建对象，不将对象分配在堆内存中，因此对象会随着线程结束而直接摧毁 TLAB：Thread Local Allocation Buffer，这是内存分配的一片缓冲区，不是前文提及的ThreadLocal。每个线程创建对象时，会在新生代中开辟一片 TLAB，用来分配一些小对象(当然，ThreadLocal所引用的对象在创建时可能也会分配在这里)。TLAB是线程私有的，因此不需要在分配时对新生代进行加锁，但面 向的对象是无法进行栈上分配的。TLAB默认只占新生代(Eden:Survivor1:Survivor2 = 8:1:1)Eden区的1%，被占满时线程就必须向Eden申请空间，如果 Eden空间不足，则触发Minor GC；如果垃圾回收后空间依然不足，则直接分配到老年代。JVM默认开启TLAB，-XX:-UseTLAB参数可以关闭。 public class EscapeAnalysis { private static Integer GLOBAL_COUNTER; // 全局静态变量 String name; // 私有属性 public String random() { GLOBAL_COUNTER = new Integer(0); // 赋值给全局变量，全局逃逸 Character[] chars = new Character[10]; Random seed = new Random(); // 局部引用，未发生逃逸 chars = Arrays.stream(chars).map(o -> (char) (seed.nextInt(26) + 'a')) .toArray(Character[]::new); String random = Arrays.toString(chars); // chars 作为参数调用，局部逃逸 name = random; // random 赋值给属性，局部逃逸 return random; // 作为返回值，局部逃逸 } } 使用1000个线程创建10000000个对象，测试TLAB的作用，开启状态下，耗时约6000ms，关闭状态耗时9000ms，开启时性能有明显提升。 public static void main(String... args) { long start = System.currentTimeMillis(); int nThread = 1000, n = 10000000; ExecutorService threadPool = Executors.newFixedThreadPool(nThread); Collection> callers = new ArrayList<>(100); List list = new ArrayList<>(n); for (int i = 0; i { list.add(new Object()); return null; }); } try { threadPool.invokeAll(callers); threadPool.shutdown(); } catch (InterruptedException e) { e.printStackTrace(); } long end = System.currentTimeMillis(); System.out.println(\"\\ntime cost: \" + (end - start) + \" ms\"); } 基于逃逸分析和栈上分配的概念，我们大概知道了对象分配的生命周期。基于GC，需要再介绍Java引用的概念： 强引用：所有直接的赋值运算都是强引用，强引用的对象只有在根搜索算法查询不到时，才会被回收，否则一直存在于老年代中，直到内存不足抛出异常 软引用：SoftReference关联的引用，与强引用相比，软引用对象在内存不足时会被GC回收。在用到大链表等场景下，可以考虑使用。 弱引用：WeakReference关联的引用，与软引用相比，弱引用在每次GC执行时都会被回收。在用到大链表等场景下，可以考虑使用。 虚引用：PhantomReference关联的引用，必须与引用队列ReferenceQueue关联，可在对象被回收时，加入引用队列。实际编码过程中几乎不用。 JVM 11的可达性分析已经非常成熟，实际编码过程中用到的工具类，基本不需要手动置空以达到协助GC的目的。如果有自行实现的链表或树等数据结构， 置空相关引用可以协助垃圾回收。参考 Object类 作为面向对象编程语言，Java的Object像Ruby一样，是所有类的父类。Object类中，有以下方法可供子类使用： getClass()：获取当前类的类对象，通常在一些判断和反射场景下用到 hashCode()：JNI地方法生成一个整型的hashCode，主要应用于依赖散列算法的地方，如HashMap。hashCode相等是对象相等的必要不充分条件 equals()：判断两个对象是否相等，主要应用于Map、Collection等。重写此函数同时应该重写hashCode()函数，两个对象应该有相等的hashCode clone()：获取该对象的深复制 toString()：将对象转化为字符串，数据实例可以重写此函数进行默认序列化 notify()、notifyAll()：唤醒一个/所有因此对象monitor锁进入WAITING状态的线程 wait()：使持有该对象monitor锁的当前线程进入WAITING/TIMED_WAITING状态，直到被唤醒或等待时间结束 finalize()：在对象被GC时，此函数会被执行。Java9及之后的版本已废弃 常用开发工具类 Java是个强类型语言，虽然新的feature已经支持类型推断和弱类型声明，但Java的本质没有改变。一些规定是很死板的，如JavaBean属性需定义为私有， 只能通过getter/setter向外部暴露值。基于这些客观事实，Java许多语法会显得极其繁琐，因此需要借助各类工具来提高开发效率。 lombok：这是一个字节码增强工具，通过注解的方式，节省数据类代码，如@Data、@Getter、@AllArgsCounstructor 、@Builder、@Slf4j、@NonNull等 Objects：JDK的Objects工具类，提供了equals()、nonNull()、compare()等一系列工具函数 Arrays：JDK的Arrays工具类，提供数组相关操作，如asList(...)、singleton()、stream()等 Collections：JDK的Collections工具类，提供集合类增强，如sort()、addAll()等 System：JDK的系统类，提供系统层面的接口，比如arrayCopy()、gc()等 Math、Random、Decimal：JDK的数学运算相关类，提供诸如其名的工具。需要进行浮点运算时，应使用Decimal的实现替代double、float等浮点类型 ObjectUtils、StringUtils：这里主要是说Spring框架的增强类，此工具类封装了诸如isEmpty()、nullSafeEquals()等判断工具，可以避免难看的空指针判断 除了上面列出的，还有许多开源库提供的工具类。这里建议以最少依赖原则引入第三方库，这样便于统一代码风格，也在一定程度上避免包冲突。 Lambda表达式和Stream API Lambda表达式和Stream API对开发者来说，是JDK8最有意义的特性之一，它极大简化了编码复杂度。Stream API针对集合数据，产生一次该集合的复制，对集 合原有数据不会造成任何影响。但计算过程中的数据就像流水一样，每个元素只能获取一次，想要再次获取，必须创建一个新的流。 import org.springframework.util.CollectionUtils; import org.springframework.util.StringUtils; import java.util.*; import java.util.stream.Collectors; public class LambdaDemo { public static void main(String... args) { List list = Arrays.asList(1, 2, 3, 4, 5, 0, 9, 8, 7, 6); // filter() 选取Lambda表达式结果为true的结果，collect() 根据Collector收集结果 List list1 = list.stream().filter(o -> o > 7).collect(Collectors.toList()); printCollection(\"list\", list); printCollection(\"list1\", list1); // sorted() 排序，可传入一个排序函数式接口 List list2 = list.stream().sorted().collect(Collectors.toList()); printCollection(\"list2\", list2); // map() 对每个元素做计算，并返回计算结果 List list3 = list.stream().map(o -> o *= 10).collect(Collectors.toList()); printCollection(\"list3\", list3); // findFirst()/findAny() 获取第一个/任意一个元素，返回一个Predict函数接口，接口判断不存在时，返回orElse的结果 int i = list.stream().filter(o -> o System.out.print(o + \" \")); System.out.println(); } } JDK8的Lambda表达式、Stream API、函数式接口还有许多应用场景，如匿名函数，函数式接口回调等。如果对此语法不熟悉，调整IDEA的语法标准(File->Project Structure->Modules->Language Level)为Java8及其以上，打开语法检查，IDEA会根据语言标准对可优化的代码进行提示，从而帮助熟悉新的语法特性。 接口、注解、反射、范型 接口：前面提到，Java语言遵循单继承、多实现的设计，因此不得不提接口(interface)。接口通常是一系列行为的集合，编程中用来声明一些函数，多个模 块互相调用时，通过接口的方式进行，而不关心具体实现，这是常见的面向接口编程思想。例如Java声明的Collection接口，ArrayList、LinkedList、 HashSet等类都是该接口的实现，它们有数组、链表、HashTable等不同的实现方式。但当我们使用诸如Stream API、Collections工具类，去进行一些操作， 比如排序时，我们只需要关心自己的排序算法的实现，而不需要关心排序对象的实现，因为获取元素的行为已经被Collection接口封装起来，我们调用排序API时， 只需要将排序对象向上转型为Collection接口就好。此外，基于这样一种固定的声明的特性，因此在RPC服务中，Java的接口通常用来作为二方包发布。 注解：注解是一类特殊的接口，它的声明方式是@interface，要使注解可以使用，需要指定注解的@Target和@Retention的值。 注解中只能声明各类行为，以及这些行为的默认返回值，但无法让具体的类去实现它。在编码过程中，我们可以在类、属性、方法、参数等地方使用注解，由@Target 的值决定；@Rentention的三个值决定了注解的生命周期，分别是Source(只在源码中可见，编译过程会忽略)、Compile(编译器会将注解 编译到class文件中)和Runtime(注解被编译到class文件中，同时可以在JVM运行时通过反射获取)。 反射：反射是Java获取类的元数据，也就是Class对象数据的一种方式。通过Class对象，我们可以获取类的属性、方法、方法的参数、注解等所有class文件 内保存的数据。基于这些数据，如方法Method，反射API提供声明式的调用，这个特性使我们只知道类限定名、字段名、函数名等场景下，可以通过名称直接调用。 这是一种灵活的设计，在JRE多次改良后，反射的执行效率已经非常高。许多基于字节码和动态类加载的框架，如ORM，使用反射进行实现。JDK提供的动态代理框架 Proxy，也是通过反射调用增强后的动态类实例，以达到代理的目的。 范型：范型是Java提供的一种编码手段，可以认为范型是针对类的一种变量，代码中的范型变量在编译时会被实际使用的类型取代。范型出现以前，类似 Collection这样的接口声明只能用Collection的方式，因为所有类都是Object类的子类。但应用时，涉及类型转换，需要将Object转换称实际使用 的类型，这增加了代码的复杂度，也可能导致类型转换的错误。范型解决了这个问题，通过编译时的隐形转换，只有匹配范型的类型才可以调用。范型参数可以通 过Class.getTypeParameters()方法获取，但这个接口只能获取声明，无法获取实际参数类型，用处不大；Class.getGenericSuperClass()方 法可以获取类的第一个父级类型，如果父级类型是带范型参数的，范型参数会一并获取，此时可以通过ParameterizedType.getActualTypeArguments() 来获取实际范型参数的类型。 public class GenericsDemo { T1 t1; T2 t2; > GenericsDemo(M map) { if (map == null) return; map.forEach((k, v) -> { t1 = k; t2 = v; }); } T1 getT1() { return t1; } T2 getT2() { return t2; } } Maven Maven是款Apache提供的Java项目构建工具，集依赖管理、编译、测试、打包、发布等功能于一身，是最常用的Java开发工具。maven的基本生命周期如下： clean：清理classPath内的文件，通常在target目录下。如果运行时发现程序结果和自己的预期不符，可以执行mvn -U clean强制清理已存在的包试试 validate：验证所有资源文件的完整性 compile：编译源码到classPath test：执行单元测试 package：将编译完的字节码文件打包，形成jar或war等可直接被jvm执行的程序 verify：运行检查，不常用，具体流程待验证 install：将打包完成的包部署到本地maven仓库(默认~/.m2/repository)下，供不同模块依赖，常用于多模块依赖项目 site：生成站点，不常用，具体流程待验证 deploy：部署项目的包到依赖的远程仓库，可用于二方包发布、覆盖等 maven可以管理多个模块，每个模块都需要自己的pom.xml文件。pom文件主要包括以下属性： parent：依赖的父级包 groupId：jar包的groupId，通常为公司/组织前缀+项目名称，如 cn.xg.study artifactId：jar包的artifactId，通常唯一标识项目模块名称，如 main-server version：jar包的版本号，groupId:artifactId:version 三个值组合一起，形成当前项目jar包唯一标识 properties：设置一些局部或全局属性，可通过 ${} 占位符进行调用 dependencyManagement：依赖管理配置，主要用于确定每个依赖包的版本，此项不会为当前项目加载被声明的包，但管理的值可以被所有子项目继承 dependencies：当前项目依赖的包，声明项会被maven加载。如果发生依赖冲突，可以通过exclusions子项排除。依赖冲突是最常见的问题，判断冲突的方 式可以使用maven dependency的结果对比，但这很低效，IDEA有个maven-helper插件，可以协助对比冲突 build：maven作为构建工具的核心，可以引入各类插件来增强maven的构建能力 modules：当前项目所包含的子模块 var gitalk = new Gitalk({ clientID: '6c5979cef62fdd9b4854', clientSecret: 'af796559c2892e1ebbf10480d8c2fc2d0bb4af24', repo: 'chainj.github.io', owner: 'ChainJ', admin: ['ChainJ'], id: location.pathname, distractionFreeMode: false }) gitalk.render('gitalk-container') © Cheng all right reserved，powered by GitbookModified At: 2021-12-10 14:21:48 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"programming/java/spring-base-1/page.html":{"url":"programming/java/spring-base-1/page.html","title":"Spring Base 1","keywords":"","body":"Spring 开发基础SpringSpringBootSpringCloudWeb项目中常用Spring组件IOC和DI常用注解Spring中的BeanSpring数据库连接池和事务一次简单的CURD开发流程Spring 开发基础 这是一篇面向Ruby语言编程者的培训文档，主要介绍Spring框架的基本概念和日常开发过程中的应用。 Spring Spring是一款用于Java应用开发的开源框架，特点是设计灵活，主要包括7个可自由搭配的组件： SpringCore：核心容器提供Spring框架的基本功能，包括Bean管理、公用工具和字节码增强工具等。核心容器的主要组件是BeanFactory，使用控制反转(IOC)模式将应用程序的配置和依赖性规范与实际的应用程序代码分开。新的版本，SpringCore和SpringBean分开，使各自职责更单一。 SpringContext：Spring上下文是一个配置文件(applicationContext.xml)，向Spring框架提供上下文信息。核心接口是ApplicationContext，基于此接口，可向所有模块提供诸如读取配置文件的实现、读取BeanFactory、推送Spring事件等能力。 SpringAOP：通过配置管理特性，AOP(Aspect Oriented Programming)模块提供面向切面的编程的能力，以解决诸如日志记录、权限验证、事务控制、错误处理等相对固定、独立的问题。使用者只需要通过定义切面(@Aspect)、切点(@PointCut)和行为(@Before、@After、@AfterThrowing等)三个概念完成对代码的织入以达到动态增强的效果。 SpringDAO：DAO提供了数据访问层的封装，可用该结构来管理异常处理和不同数据库抛出的错误消息。异常层次结构简化了错误处理，并且极大地降低了需要编写的异常代码数量。 SpringORM：ORM层提供了对象/关系映射工具，JPA、Hibernate、MyBatis等框架都可以基于此模块集成到Spring，所有这些都遵从Spring的通用事务(spring-tx)和DAO异常层次结构。 SpringWeb：Web包提供了基础的针对Web开发的集成特性，例如多方文件上传，WebApplicationContext初始化等。基于Servlet API，SpringWeb可以集成Struts等框架。 SpringMVC：MVC框架是一个全功能的构建Web应用程序的MVC实现。通过可自由接入的Interceptor、Filter，以及Databind等接口，其核心类DispatcherServlet，可以实现url映射、请求拦截及数据绑定(参数数据反序列化、字段校验)等任务。controller完成处理后，通过ModelAndView进行返回数据处理。 SpringBoot SpringBoot是基于Spring框架搭建的一个，以快速构建、独立运行为目的应用构建框架。它和Spring框架的最大区别是，Spring是一款为编写应用设计的框架，而SpringBoot是为构建应用设计的框架。它更多是提供各类灵活可用的构建工具，如基于main函数的web应用启动器、内嵌的tomcat容器等。虽然我们大部分情况下都是构建Web应用，但SpringBoot并不是只为Web设计的，它可以作为一个单纯的计算应用，可以作为一个文件处理应用。使用什么样的组件，取决于用户需要SpringBoot构建什么样的应用。基于这种小而精的理念，SpringBoot在构建微服务方面尤其受欢迎。 SpringBoot在需要使用这些具有不同功能的模块时，不需要使用者自己完成各个模块的加载，而是会根据starter完成自动加载。因为SpringBoot启动时，会加载classPath和extLibrary下jar包的META-INF文件夹，读取spring.factories文件，并根据声明项读取相关的类完成ApplicationContext的初始化。根据这个特点，我们也可以实现自己的starter。 SpringCloud SpringCloud是基于SpringBoot的一个分布式微服务架构。每个用户自实现的SpringBoot可以提供Web服务，而SpringCloud框架则在SpringBoot的基础上，根据配置，提供服务网关(ZUUL)、配置中心(Config)、服务发现(Eureka)、负载均衡(Ribbon)、降级熔断(Hystrix)、RPC调用(Feign)等功能。 Web项目中常用Spring组件 Spring框架集成了许多通用组件，只需要简单的配置就可以使用。SpringBoot项目下，配置文件默认为application.yml，与Spring框架相关的通用配置项在spring配置下，不同环境通过application-{env}.yml这样的配置文件区别。application.yml同时可以代替掉传统的各类properties配置文件，但如果配置项太多，还是建议单独写配置文件。 开发通用：RestTemplate、RedisTemplate、MongoTemplate、ScheduledTask、KafkaClient等 Mybatis/Mybatis-Plus：ORM实现框架，配置项写在mybatis/mybatis-plus下，核心配置项是mapper-locations，指定mapper文件位置 日志组件：springboot默认使用logback框架作为日志组件，它是一个slf4j的实现。默认配置文件为logback-spring.xml，主要需要设定日志appender，分ConsoleAppender和RollingFileAppender两种 测试组件：除了传统Java程序的Junit框架，SpringBoot在此基础上提供了SpringBootTest，来提供单元测试使用的容器环境，我们的项目采用的这种方式。测试提供的容器和应用运行时的容器没有区别，如果不希望在测试时形成真实的数据库变更，有时需要配合一些错误或Mock工具完成测试。常用的Mock工具有EasyMock、Mockito等 IOC和DI IOC(Inversion of Control)，控制反转是软件设计中的一种方法论，也是在Java开发群体中被广泛认可的提倡的一种设计。而DI，在Java的演变历史中，是IOC的一种具体实现。DI(Dependency Injection)的核心是，如果A依赖B，则由B自己完成实例化，并通过setter或constructor的方式，为A提供自己的实例。 Spring的IOC容器实现是一个Map，key通过beanName唯一标识一个Bean实例，而value则描述一个可实例化的BeanDefinition对象接口。SpringBoot项目启动，会对ApplicationContext/WebApplicationContext进行初始化，由context根据配置文件或Bean注解，去扫描所有应该创建的实例，然后循环解决每个实例间的依赖，直到找到无依赖或相互依赖的Bean，然后反射创建对象，再通过setter/constructor完成依赖注入。如果对源码感兴趣，可以关注AbstractApplicationContext(可视作容器，获取bean通过此类调用)、AbstractBeanFactory、DefaultListableBeanFactory (Map容器本身)、DefaultSingletonBeanRegistry(解决循环依赖，完成实例化)。 常用注解 Spring从2.0开始，提供各类注解来简化配置，开发中常用的注解有如下一些： @Bean、@Component、@Service、@Repository：这几个注解都是标识一个类是一个由IOC容器创建、管理的Bean，通常@Bean和@Component用来标识一些普通的Bean或提供公共能力的组件，@Service标识业务处理的服务类，@Repository标识数据访问类 @Autowired、@Resource、@Value：将受容器管理的Bean注入到当前类中。@Autowired自动根据对象类型注入，@Resource默认根据名称注入，@Value用来注入配置文件中的属性。只有注入对象是受IOC管理的Bean才会生效。 @Configuration：标识配置类，可用于代替xml文件。容器初始化时会去扫描配置类下所有方法，并将声明的Bean注册到容器中 @Controller、@RestController：标识Http请求的处理类，@RestController是在@Controller的基础上，增加了@ResponseBody，使得此注解下所有方法的返回结果会被解析为json格式 @RequestMapping、@RequestParam、@PathVariable、@RequestBody：Http请求的解析注解，@RequestMapping标识uri，@RequestParam绑定query参数，@PathVariable绑定路径参数，@RequestBody绑定请求体。注解在不指定名称的情况下，默认使用参数名称绑定。如果不使用注解，SpringMVC会尝试自动根据参数的名称和数据类型进行绑定 @Entity、@Table、@Column、@Id：ORM相关注解，分别标识实体、数据表、列、主键，用来解决实体和实际表间的映射问题 @Query、@Select、@Update、@Delete：注解式声明DAO查询语句，免去xml编写 @Transactional：声明Spring事务的注解，利用AOP在修饰代码块的数据库访问中添加事务，以提供事务提交和回滚的能力 @Async：配合线程池配置使用，可以利用线程池内的线程启动异步任务 @Aspect、@PointCut：声明切面、切点，实现AOP // 容器初始化时，加载@Configuration，代替配置文件 @Configuration // 引入其它配置文件，其它文件只需要声明配置项内容，不需要添加@Configuration @Import({GlobalConfig.class, RedisConfig.class}) public class Config { // 读取配置文件中的 spring.application.name 属性值，注入到name字段中 @Value(\"${spring.application.name}\") String name; @Bean RestTemplate restTemplate(){ // 初始化一个名为restTemplate的bean return new RestTemplate(); } } Spring中的Bean Bean这个词在Java相关的资料中可能随处可见，我们不再去深究它的起源和演变，我们只说说什么是标准的Spring中的Bean。Spring中的Bean是可以交给IOC容器创建、管理、销毁的Java实例，因此它需要具备以下特性： 无状态，或者说状态都由容器管理。Bean的所有可变属性应该由@Autowired、@Resource、@Value的方式注入，如果需要定义可被业务代码修改的属性，必须考虑线程安全问题 Bean有单例、原型两种常见模式，默认为单例。Web场景下，还有Request、Session、GlobalSession模式，对应Bean的生命周期为单次请求、Session范围和全局Session范围 Bean通过name属性唯一标识，通常情况下，Bean的类型可以做到这件事，但如果同一个类有多个实现时，必须指定Bean的名字 Spring数据库连接池和事务 数据库连接池随应用启动而创建并完成初始化，每个线程在访问数据库时都向连接池申请连接，完成连接和线程的绑定，使用结束再归还。基于常见的Web应用线程模型(如tomcat)，每个http请求创建一个新的线程去执行。在线程调用到有@Transactional注解修饰的代码块，Spring执行事务增强。事务切面会从ThreadLocal对象中，获取当前线程的连接(如果已完成绑定)，或从连接池申请一个连接并写入到当前线程ThreadLocal对象以完成连接和线程绑定，之后执行事务开始语句。如果线程的调用链中，存在多个@Transactional，Spring会根据其传递性插入不同的语句。根据这个模型，如果线程的调用链中新起了一个线程，新起的线程会获取一个新的连接并开启新的事务去完成自己的数据库操作，所以“主”线程的提交、回滚等操作对其“子”线程没有任何影响。 Spring的事务是基于AOP实现的，而AOP的默认实现是JDK的Proxy。Proxy实现动态代理时，只能增强接口，所以有以下限制： @Transactional只对public函数生效，因为接口声明的函数都是public的 只能通过外部调用触发事务，同一个类内部互相调用，不能触发事务 未处理和指定声明的异常才能触发回滚 Spring事务传递性，TransactionDefinition： PROPAGATION_REQUIRED：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务 PROPAGATION_REQUIRES_NEW：创建一个新的事务，如果当前存在事务，则把当前事务挂起 PROPAGATION_SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行 PROPAGATION_NOT_SUPPORTED：以非事务方式运行，如果当前存在事务，则把当前事务挂起 PROPAGATION_NEVER：以非事务方式运行，如果当前存在事务，则抛出异常 PROPAGATION_MANDATORY：如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常 PROPAGATION_NESTED：如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价PROPAGATION_REQUIRED 一次简单的CURD开发流程 Controller：用于接收和处理HTTP请求，使用@Controller或@RestController修饰，使用@RequestMapping指定uri。Controller在SpringMVC中默认是单例实现的，即所有请求到来时，调用到的是同一个对象的方法。因此Controller中，不被Spring容器管理的属性不是线程安全的，如果有必要增加这些属性，需要考虑其线程安全问题。 Service：主要用于处理复杂的业务逻辑，向上为Controller层提供服务，向下调用DAL层的接口完成数据操作，事务处理通常也在这一层。使用@Service修饰，需要声明一个接口xxxService供上层调用，再编写一个实现类xxxServiceImpl。 DAL/Repository：完成数据库增删查改实现，向上为Service层提供服务。使用@Repository修饰，需要声明一个接口xxxDAO/xxxRepository，再编写实现类xxxDAOImpl。 ExceptionHandler：SpringWeb提供@ExceptionHandler和@ControllerAdvice来协助完成全局异常处理。Java提供异常处理机制，在编码过程中，通常我们都需要一个随处可用的异常来使得程序及时感知一些不符合逻辑或未知错误，RuntimeException是一个更好的选择，因为它不像Exception一样，需要显式处理。基础架构组提供了BizException来统一处理，如果编码过程中发现这个类不能满足需求，我们也可以自己定义一些继承自RuntimeException的异常类，并使用@ExceptionHandler声明对此类异常的处理流程。 可能Service层和DAL层，每个组件都要先声明一个接口再完成实现类的方式大家不太明白为什么要这样做，这是硬性要求吗？对此我是这样理解的： Spring框架的AOP是基于Proxy的，而JDK的Proxy需要基于接口实现动态代理。所以不声明接口的话，Spring的许多特性，比如事务等，需要使用其它方式实现。 这不是硬性要求，但是这是提倡的做法。稍大一点的项目，在编程过程中，先约定好interface，再做实现可以很好的切分职责，独立开发。比如A、B两个后端同学协作开发一个项目，A对B负责的领域不太熟悉，这时候先让B在自己的领域服务上提供一个接口定义，A在有此接口定义的情况下可以自由开发、测试，不会因为没有实现导致自己开发过程中的编译错误。 其实第二点说的核心，就是面向接口编程的思想。无论是前后端交互，还是后端服务间交互，甚至一个项目中不同模块间的交互，所有的约定，在Java中都可以看作一个接口。有的RPC框架，如阿里的HSF，就是基于接口声明完成调用的。此外，接口因为其轻量的特性，还可以单独提取出来发布成二方包，供其它人使用。 var gitalk = new Gitalk({ clientID: '6c5979cef62fdd9b4854', clientSecret: 'af796559c2892e1ebbf10480d8c2fc2d0bb4af24', repo: 'chainj.github.io', owner: 'ChainJ', admin: ['ChainJ'], id: location.pathname, distractionFreeMode: false }) gitalk.render('gitalk-container') © Cheng all right reserved，powered by GitbookModified At: 2021-12-10 14:21:45 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"database/":{"url":"database/","title":"Database","keywords":"","body":"DatabaseDatabase Redis why-complexity-of-zrem-is-logN © Cheng all right reserved，powered by GitbookModified At: 2021-06-21 20:53:27 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"database/redis/":{"url":"database/redis/","title":"Redis","keywords":"","body":"RedisRedis © Cheng all right reserved，powered by GitbookModified At: 2021-06-21 20:52:05 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"software-engineering/":{"url":"software-engineering/","title":"Software-Engineering","keywords":"","body":"Software Engineering定义背景知识体系软件生命周期工程软件质量目标和意义Software Engineering 定义 Software Engineering is the systematic application of engineering approaches to the development of software. --Wikipedia 软件工程是一系列软件开发的工程方法的系统性应用，它强调系统性地、有组织地、标准化地对软件进行开发、演进和运维。 软件工程与计算机科学的区别是，计算机科学着重于学习算法、运算硬件以及运算本身，而软件工程着重于计算机科学知识的实践问题。简单说，计算机科学教我们计算机如何工作，而软件工程教我们怎么用计算机工作。 工程重在实践和交付。对于软件工程来说，低成本、高质量的交付产品是最终目标。因此，软件工程的理论和方法贯穿软件的整个生命周期： 需求分析 系统设计 开发测试 部署运维 系统维护 软件工程的定义取自IEEE的标准定义，虽然随着技术演进，这个定义有一定争议性，但我们还是取用此标准加以解释 背景 1946年，曼哈顿计划孕育了世界上第一台可编程的计算机——ENIAC 1948年，世界上第一个软件在曼切斯特大学运行 五十年代初期，第一个操作系统在IBM的主机上运行 1958年，统计学家 John Tukey 创造了 software 这个词 六十年代，软件行业迅速发展，软件质量稂莠不齐，出现 软件危机 六十年代末期，为了应对 软件危机 ，软件工程 应运而生 软件危机 主要包括以下问题： 没有标准和流程，大量软件项目因预算超支等问题失败 大型软件维护成本过高 交付的软件不可靠，无法满足需求 软件迭代速度跟不上需求变化速度 软件开发速度跟不上需求增长速度 工程师们尝试在实践中去制定一套需求分析、软件开发和系统交付的衡量标准，这就是 软件工程。 知识体系 软件工程发展的过程中，产生了许多概念和方法论，我们无暇一一例举，但有一点是清晰的：所有的方法论都是围绕 软件生命周期 展开的。 软件生命周期（SDLC） 是一种软件开发过程的方法论，主要包含以下过程： 需求分析 规划 设计 开发 测试 部署维护 这张图的划分并不严格，实际上我们也没法对所有事物进行严格划分，因为用发展的眼光看事物的话， 定义 是一直在变化的。 横看成岭侧成峰，同一个事物，从不同角度解析，可以得出不同的结论。比如图中的软件架构的三个子项 微服务 、 事件驱动 和 云服务 架构，他们并不是互斥的关系，微服务架构也可以设计为事件驱动型架构。换个角度，软件架构可划分的角度很多，远不止罗列的这三项。这个图之所以画出这一部分，主要还是想和大家呈现，我们用到和经常接触的一部分概念。 从图中的关系可以看到，所有的工程方法都是为提升 软件质量 服务。 软件生命周期 Software Development Life Cycle 工程 软件设计 软件设计8原则： Keep It Simple Don’t Repeat Yourself You Aren’t Gonna Need It SOLID Single Responsibility Principle Open Closed Principle Liskov Substitution Principle Interface Segregation Principle Dependency Inversion Principle 设计模式 Design Pattern 过程模型 敏捷模型 Agile 敏捷方法： SCRUM XP FDD LEAN DEVOPS 软件质量 Software Quality 8个指标: 代码质量 可靠性 性能 可用性 正确性 可维护性 完整性 安全性 通用标准： CMMI 软件质量分级 目标和意义 随着硬件水平的进步和市场规模的变化，软件工程的理论也在与时俱进。理论是同行前辈经验的积累，选择有效的理论进行实践，可以有效提升实际生产中的效率。但理论的实践方法不胜枚举，如何在实践环节中，选择适合团队的方法进行组合，最终形成最佳实践，这是我们应该努力探索的。 var gitalk = new Gitalk({ clientID: '6c5979cef62fdd9b4854', clientSecret: 'af796559c2892e1ebbf10480d8c2fc2d0bb4af24', repo: 'chainj.github.io', owner: 'ChainJ', admin: ['ChainJ'], id: location.pathname, distractionFreeMode: false }) gitalk.render('gitalk-container') © Cheng all right reserved，powered by GitbookModified At: 2021-12-10 14:19:53 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"software-engineering/efficiency-engineering/":{"url":"software-engineering/efficiency-engineering/","title":"efficiency-engineering","keywords":"","body":"Efficiency EngineeringEfficiency Engineering © Cheng all right reserved，powered by GitbookModified At: 2021-06-21 21:31:16 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"software-engineering/efficiency-engineering/practice-agile-with-TBD/page.html":{"url":"software-engineering/efficiency-engineering/practice-agile-with-TBD/page.html","title":"Practice Agile with TBD","keywords":"","body":"Practice Agile with TBD一个小问题的思考什么是TBD我为什么推荐TBDTBD和敏捷有什么关系如何在实践中更好地应用TBD总结参考资料Practice Agile with TBD 一个小问题的思考 日常的开发和测试工作中，你是否有以下烦恼? 分支生命周期过长，协作开发困难 不敢轻易改动他人的代码，不敢重构 为杂乱无序的提交记录费神，疲于解决提交冲突 不同环境测试的代码具有不确定性 为了保证合并代码不出错，反复进行回归测试 Git为开发和测试提供了一个高效的工具，但往往我们在使用的过程中没有发挥出他最大的潜力，甚至因为使用不当，人为造成不必要的问题。 我们的开发流程是比较标准传统的 GitFlow 分支开发流程： 研发基于不同的特性拉取不同的 Feature 分支进行代码开发 开发完成之后，合并到 dev 分支，在开发环境完成联调和自测 自测完成，合并代码到 qa 分支，由测试开始执行测试用例 测试通过，合并代码到 release 分支并发布到预发布环境，由测试利用线上数据进行回归测试 回归完成，合并代码到 master 分支并发布到生产环境，由测试和产品回归和验收产品功能 整个流程涉及4次必要的代码合并和2次必要的回归测试流程。这种情况下，即使回归测试已经比较全面了，是否能保证上线的代码足够可靠呢？ 近期我们团队在发布的时候发生了两个小插曲： 合并代码到 master 分支，没有任何冲突，但发布上线后发现代码错误 合并代码到 master 分支的过程中，对冲突不够熟悉，选择了错误的代码 这些问题可以通过分支管理规避吗？请往后看。 什么是TBD Trunk-Based Development 主干开发模式是一种源码管理模型。如它的名字描述那样，开发者大部分时候都在一个被称为 主干 的分支上完成协作。开发者每完成一个任务，即将代码合并到主干分支，以便所有协作者都可以最快同步到最新变更。 与之对应的是 Feature Branch Development 。开发者基于不同的特性构建不同的 feature 分支，在完成目标开发后再合并到主干分支，以完成测试、发布等工作。 FBD TBD 举一个我们团队中的开发、提测、发布流程为例 FBD 进行三个小功能的开发，其中真正的冲突只存在于F1和F2之间，但FBD的模式形成了6次冲突。其中需要研发人员手动解决的有3次，其余3次虽然可以自动解决冲突，却无法应用fast-forward。因此master、dev和qa分支会存在非常多的因自动合并而形成的提交，影响分支功能的理解。 TBD 冲突只存在于F1和F2，只需解决一次冲突。开发联调、测试和发布，均基于trunk分支本身，或trunk分支的提交构建Tag或Release。trunk分支始终处于非常干净的状态，不会有自动合并产生的无意义提交。 我为什么推荐TBD Branching is easy, merging is harder. TBD的初衷是尽量减少代码冲突，提升开发效率和代码的正确性 冲突会带来什么问题？ 解决冲突可能导致代码错误 冲突解决后需要测试回归 频繁解决冲突会中断研发同学的工作，降低研发效率 生命周期过长的分支，在解决冲突时需要耗费额外的沟通成本 我们希望： 测试完成工作后，不需要跟研发沟通合并分支、解决冲突等，而是可以自行进入发布流程 所测即所得，不同测试、集成环境只有数据不同，不会存在代码上的差异 分支生命周期足够短，每次合并尽量解决小的、近期开发过的冲突 避免重复工作，同样的冲突解决一次就可以上线 无负担地进行代码重构、升级，而不必担心重构带来的冲突和正确性问题 TBD的优势： 合作者可以在较短时间内同步到最新代码，减少不必要的差异，在3-5人的敏捷团队，表现更佳 研发人员不必花费额外的精力和重复工作去介入测试、发布等工作（如合并feature到master） 研发和测试工作隔离，工作记录通过代码提交即可反应，节约沟通成本 代码提交记录干净清晰，可以快速明确每次提交的内容 即使使用feature的分支开发，其生命周期也较短，有利于减少冲突 TBD的劣势： 提交的代码应该是可上线的，这对研发和测试都是一个挑战 要求较高的代码质量管控，包括代码审核和完整的单元测试 Trunk分支和FBD模式的Master分支相比，具有更低的稳定性 TBD和敏捷有什么关系 敏捷致力于使团队以小而可行的增量形成轻量级交付。通过需求评审、工作计划、结果交付，这些流程的持续进行，使得团队可以快速应对变化。 敏捷的特点： 小而美 增量可行 持续集成 持续交付 多做计划 快速迭代 拥抱变化 TBD的特点： 轻量提交 快速合并 持续集成 测试驱动 实时反馈 持续集成 是保证敏捷快速迭代、持续交付的核心环节，也是TBD中保证代码质量和正确性的重要手段。因此基于轻量快捷的提交和持续集成等特性，TBD是一种非常适合在敏捷团队中应用的分支管理模型。 在TBD的日常应用中，研发注重的是代码质量和单元测试（覆盖冒烟用例），不再花大量精力关注提测后变动，如版本管理、发布上线等。测试驱动 和 持续集成 保证TBD以一种良好的正向循环模式运作。 如果测试发现BUG，研发在最新的代码上进行修改，测试也会在最新的代码上进行验证。由于主干分支在大部分情况下是持续可发布的，测试可以根据自己的工作情况随时安排发布上线。 持续集成 对比瀑布模型，敏捷强调测试提前介入到需求分析和技术方案评审中，通过前期的沟通充分了解需求和技术方案。而在TBD的基础上，研发强调代码快速集成、持续部署。通过这样的方式，迫使测试提前介入到对研发任务的了解中，这是一件相辅相成的事。 基于TBD，团队协作变得更简单 如何在实践中更好地应用TBD 对研发： 尽量小的提交代码，高效快速完成code review 每次提交的代码尽量做到向前兼容 重要模块编写完整的单元测试，每次提交保证测试通过 持续集成，持续部署，尽快让最新的代码进入QA等流程接受回归测试 适当结合feature开发，如大特性、无法向前兼容的变更等 给予测试足够的信心，认可持续性地集成测试能覆盖足够的场景 对测试： 熟悉Git，了解常用的分支操作，可以根据需要构建自己的Release分支 关注代码，理解交付的任务和代码间的关系，可以根据需要构建特定功能分支 非必要的情况下，在主干分支完成测试工作，Release分支通常只用于上线前的集成回归或者上线后的热修复验证 给予研发足够的信心，相信研发主观判断和客观结果（单元测试） 结合敏捷，我们可以这样做： 以任务维度形成提交，提交描述应该反应任务内容，任务也可以是代码重构，可以是版本升级等 以故事维度提测，确保主干分支集成的代码是可发布的，提测的形式可以是一个部署包或者一次完整提交 以Tag/Release形成发布，通常只需要通过在主干上选取需要发布的提交命名为Tag。如有必要，可以拉取Release分支，并拣取需要发布的feature提交进行发布（这种情况通常只发生在hotfix或主干分支有很少部分最新提交需要上线，但其余提交还未验证的情况下） 为了使主干分支的提交在迭代需求上符合随时上线的条件，在做迭代planning时，应该尽量保证短周期需求的稳定性，这也是敏捷要求的 总结 无论是敏捷还是TBD，目的都是为了提升开发效率，选择最适合团队的方法才能最大程度地提升效率。 现在我们团队还是以大版本、大项目为基础做计划，偏瀑布式的项目管理和开发模型，这可能更适合部分大客户的定制需求，但不利于快速迭代和交付。从进入公司到现在，最大的感受是开发多线并行，前后端进度不一致，测试疲于应付。虽然我们在使用迭代，但多个迭代并行，占用共同资源，迭代无法如期进行的情况还是存在的。 每个人的精力有限，同时处理多件事情必然使个体的效率下降，导致整体效率下降。 如果想轻装上阵，灵活应变，加速冲刺，不妨试试做好计划，集中资源的迭代方式。 拥抱敏捷与TBD吧！ 参考资料 Branching Pattern TBD vs FBD Continuous Integration CI in Agile var gitalk = new Gitalk({ clientID: '6c5979cef62fdd9b4854', clientSecret: 'af796559c2892e1ebbf10480d8c2fc2d0bb4af24', repo: 'chainj.github.io', owner: 'ChainJ', admin: ['ChainJ'], id: location.pathname, distractionFreeMode: false }) gitalk.render('gitalk-container') © Cheng all right reserved，powered by GitbookModified At: 2021-12-10 14:20:30 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"software-engineering/efficiency-engineering/use-git-elegantly/page.html":{"url":"software-engineering/efficiency-engineering/use-git-elegantly/page.html","title":"Use Git Elegantly","keywords":"","body":"更优雅地使用 Git一个小问题的思考杂乱无序的提交记录更优雅地合并更优雅地提交使用githook验证提交信息更优雅地管理分支更优雅地使用 Git 一个小问题的思考 日常的开发和测试工作中，你是否有以下烦恼? 分支生命周期过长，协作开发困难 不敢轻易改动他人的代码，不敢重构 为杂乱无序的提交记录费神，疲于解决提交冲突 不同环境测试的代码具有不确定性 为了保证合并代码不出错，反复进行回归测试 Git为开发和测试提供了一个高效的工具，但往往我们在使用的过程中没有发挥出他最大的潜力，甚至因为使用不当，人为造成不必要的问题。 我们的开发流程是比较标准传统的 GitFlow 分支开发流程： 研发基于不同的特性拉取不同的 feature 分支进行代码开发 开发完成之后，合并到 dev 分支，在开发环境完成联调和自测 自测完成，合并代码到 qa 分支，由测试开始执行测试用例 测试通过，合并代码到 release 分支并发布到预发布环境，由测试利用线上数据进行回归测试 回归完成，合并代码到 master 分支并发布到生产环境，由测试和产品回归和验收产品功能 整个流程涉及4次必要的代码合并和2次必要的回归测试流程。这种情况下，即使回归测试已经比较全面了，是否能保证上线的代码足够可靠呢？ 近期我们团队在发布的时候发生了两个小插曲： 合并代码到 master 分支，没有任何冲突，但发布上线后发现代码错误 合并代码到 master 分支的过程中，对冲突不够熟悉，选择了错误的代码 这些问题可以通过分支管理规避吗？请往后看。 杂乱无序的提交记录 Git为开发和测试提供了方便且优雅的版本管理工具，但不同的人有不同的使用习惯，因此会产生不同的问题。 还是以上一节提到的合并小插曲为例，在我们发现 master 分支的代码不是我们想要的代码后，我们选择了如下处理方式： 使用 master 分支和正确代码分支做对比 利用对比工具，将正确代码分支上，我们认为正确的代码选择到 master 分支上，形成一次新的提交 这确实是一种解决冲突的方式，在开发流程中的一些场景下会有不错的效果（比如两个同时开发的分支 feature1 和 feature2 ，双方有一部分共用代码，但又不想合并开发，这时可以选择上述方式拣取需要的代码部分）。但在进入测试和发布流程后，这种处理方式就欠妥了。 这样的方式会导致以下问题: 拣取过来的部分代码形成了新的提交，这个提交与原有代码没有任何逻辑上的关系。当我们需要再次合并原提交所在分支时，这次拣取所遇到的冲突，下一次合并还会遇到 原代码分支是经过测试和回归的，但通过对比拣取的方式选取代码到新的分支上，这个过程会导致代码变更，意味着对比拣取后的代码，需要重新进行回归测试 如果代码提交记录是下面这样，测试会不会觉得头大崩溃？ 9个提交记录里面只有2个提交描述是有用信息，其它的要么是因为合并冲突而生成的无意义提交，要么是没有是指信息的提交描述。如果一个开发或者测试想根据提交信息追本溯源，面对这样的提交信息他该怎么办？ 造成上图问题的主要原因有三个: 不当的Git使用方式，打乱了提交间的逻辑关系 提交信息填写过于随意，没有描述清楚代码变更的作用，也无法对应上日常工作的内容 不当的分支管理导致了不必要的冲突 那么如何解决这几个问题呢？ 更优雅地合并 \"Git’s philosophy is to be smart about determining when a merge resolution is unambiguous, but if there is a conflict, it does not try to be clever about automatically resolving it. \" Git是什么我想大家都清楚，常见功能也都很熟练，我就不过多介绍了。这一节我们主要集中在冲突这个概念上，因此我们不得不先复习一下Git的合并流程。 合并操作有多种策略，默认策略是resursive，递归三路合并: 从两个待合并的提交 head1、head2 上，寻找最近的公共祖先 ancestor 如果存在两个公共祖先，以两个公共祖先为基础执行步骤1 （递归） 如果 head2 的祖先是 head1 本身，执行 Fast-Forward 策略，直接改变 head1 指向 head2，合并完成 进行对比 head1 diff ancestor = diff1， head2 diff ancestor = diff2，根据 diff1 diff2 判断是否冲突 如果存在冲突，中断，等待解决冲突 形成新的提交（即自动形成的 \" Merge head2 into head1 \"），head1 指向新的提交 从这里，我们发现了前文提到的杂乱且无实际意义的提交记录是怎么来的。 如何避免这些记录呢？答案也在合并策略中。 第三点我们提到，如果待合并的目标提交的祖先就是当前提交，会触发 Fast-Forward 策略，只是改变当前 head 指向，不需要形成新的提交来记录这次合并行为。 要做到这一点，我们需要借助三个常用的命令， git rebase 、 git cherry-pick 和 git stash。什么情况下使用它们呢？ 执行 git merge 之前，先执行 git rebase，确保被合并的分支的祖先是当前分支 head 不要直接执行 git pull ，在本地有和远端分支不同的提交记录的情况下，执行 git pull --rebase，保证本地提交的祖先节点是远端分支的提交 不想合并分支，只需要其它分支的某一个提交时，使用 git cherry-pick，效果和使用对比工具拣取需要的代码差不多，但会获取整个提交 如果本地同分支有变更尚未形成提交，但又需要同步远端代码，可以使用 git stash将变更暂存起来，执行完git pull之后，再执行git stash --pop释放暂存区变更 以上几个命令使用起来并不复杂，但却带来了以下好处: 大幅减少合并过程中的冲突，如果我们使用gitlab的MergeRequest进行合并，rebase操作几乎是必须的 使提交间的逻辑关系更加清晰，有助于研发和测试追溯变更，同时也能减少后续提交发生冲突的概率 rebase在提交次数较多且差异较大的情况下，并不友好，可能出现多次解决冲突的问题。这种情况有两种解决方案: 在被中断时，使用 git rebase --skip 继续，到最后一次提交的时候一起解决冲突 直接使用git merge，一次性解决冲突，形成一次新的提交 上述情况在代码同步频率得当的情况下很少发生 更优雅地提交 前一节的两个命令解决了不规范合并的问题，还有一个问题是如何让提交信息更有价值？ 如何定义一个提交信息是否有价值呢？通过经验，我们认为有价值的描述具备以下几点特性: 阐述清楚变更的作用（必备） 简单描述程序实现思路（推荐） 提醒需要特别注意的地方（推荐） 包含需求来源（强烈推荐） 首先是变更的目的或者说作用，我们推荐使用以下几个词来表述常见场景的变更: feat: feature，特性，提交是为了完成某个需求或功能，强烈建议附加实现方案描述和需求来源链接，通常对应一个开发任务 fix: 修复，提交是为了修复某个已提测的问题，通常关联一个提测后的BUG单 hotfix: 热修复，指提交是为了修复某个线上问题，需要快速发布，通常关联一个线上BUG单 refactor: 重构，提交是进行代码结构或设计的重构，通常需要回归测试 chore: 杂项，提交完成一些日志、注释、文档编写，或是构建工具等变动，通常不需要回归测试 test: 测试，单元测试、集成测试编写，通常不需要回归测试 示例: feat: 添加《Use Git Elegantly》博文 说明: 1.从《Practice Agile with TBD》中拆分冗余博文内容 2.增加git实现原理部分章节 链接: https://www.tapd.cn/123/prong/tasks/456 为了强化团队协作的一致性，在大家都达成共识后，我们可以基于githook对提交信息进行验证，甚至将提交与具体的任务进行关联等。 如何使用githook，有机会我们单独讨论一下，这里不做过多说明。 使用githook验证提交信息 To Be Done 更优雅地管理分支 更优雅的分支管理策略 var gitalk = new Gitalk({ clientID: '6c5979cef62fdd9b4854', clientSecret: 'af796559c2892e1ebbf10480d8c2fc2d0bb4af24', repo: 'chainj.github.io', owner: 'ChainJ', admin: ['ChainJ'], id: location.pathname, distractionFreeMode: false }) gitalk.render('gitalk-container') © Cheng all right reserved，powered by GitbookModified At: 2021-12-10 14:20:33 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"practice/":{"url":"practice/","title":"Practice","keywords":"","body":"PracticePractice Designs in Practice © Cheng all right reserved，powered by GitbookModified At: 2021-09-07 15:07:14 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"practice/vote-design/page.html":{"url":"practice/vote-design/page.html","title":"Vote Design","keywords":"","body":"通用点赞系统设计方案业务场景方案一：基于优先队列方案二：基于关系型数据库方案三：基于缓存 + 消息队列 + 关系型数据库性能测试测试场景测试结果Redis 测试情况Mysql 测试情况Redis + Kafka + Mysql 测试情况接口测试Redis 测试情况Mysql 测试情况Redis + Kafka + Mysql 测试情况总结后记通用点赞系统设计方案 近期接到一个点赞系统的需求，回想起以前也做过类似的需求，需求核心一致，但侧重点不同。借机梳理一下常见点赞系统的业务特点，并形成一个通用设计。 文中的 点赞 只是一种业务场景，此设计可扩展到 已读、收藏 等需要记录计数和部分元数据的场景，不过多叙述 业务场景 点赞常见的业务场景，大体上分为三类： 以数量展示为主的场景，用户对数量的变动非常敏感，对计数访问频繁，如知乎、B站、Quora等 对数量和点赞用户变更都比较敏感，有时间线需求，如微信朋友圈、微博等 对业务扩展性要求较高，但对系统并发度没什么要求 这三类业务场景有一些共同的业务特点： 对计数敏感，统计数量和是否点赞是高频访问场景 要求较高的可用性（响应速度）和一致性 对点赞用户敏感，如查询点赞历史，查询共同点赞用户等 对点赞时序敏感，如关注前百名点赞用户 可能会基于时间纬度进行数据查询，如查询一天内的点赞用户等 把这些业务场景转化为具体系统功能： 查询点赞数目 查询用户是否已点赞 点赞/取消点赞 查询点赞历史 这些系统功能转化为技术需求就是： 需要实现一个计数器 需要维护用户和点赞对象之间的关系 需要记录行为时间 接下来我们根据不同的业务场景和系统要求，进行技术方案设计。 方案一：基于优先队列 选型: Redis 基本设计 以点赞主体的唯一键建立ZSet 以点赞用户ID和类型作为ZSet元素 以点赞时间作为ZSet的Score 如果需要从用户维度查询点赞记录，以用户为主体建立ZSet 主要业务场景实现方案 点赞数 zcard O(1) 是否点赞 zsocre O(1) 点赞/取消点赞 zadd/zrem O(log(N)) 查询点赞历史 zrangebyscore O(log(N)+M) 业务时序 设计优势 高可用（并发响应）、高一致性，可以较好支持ToC的场景 常见业务场景运算快速 易扩展。千万级别的数据量，Redis单机可以支撑，如果数据量增长，可以基于Cluster模式实现水平扩展。 设计缺陷 可能存在数据丢失，但在点赞这个业务场景下是可接受的 存在数据量过大的风险，需要对数据增长速度做好评估 方案二：基于关系型数据库 选型: Mysql 基本设计 保存点赞主体ID、用户ID、行为时间以及部分扩展性的元数据 以点赞主体的唯一键和用户ID建立唯一索引 如果需要以用户维度查询点赞记录，对用户ID建立索引 如果对行为时间敏感，可以对行为时间创建索引 主要业务场景实现方案 点赞数，利用点赞主体索引进行聚合查询 O(log(N)+M) 是否点赞，利用点赞主体和用户为索引进行查询 O(log(N)) 点赞/取消点赞，利用点赞主体和用户为索引插入或删除数据 O(log(N)) 查询点赞历史，利用点赞主体索引进行查询 O(log(N) *log(M)) 业务时序 设计优势 高一致性，不会因为数据库宕机造成数据丢失 更好的扩展性，磁盘空间充裕，可以支持更丰富的业务扩展设计 更低实现成本，不会因为数据量过快增长产生硬件焦虑 设计缺陷 可用性较低，应对并发度稍高的场景会存在性能问题 主要业务场景的实现复杂度比方案一更高，在 log(N) 到 M*log(N) 之间 水平扩展性较低，需要手动进行分库分表等设计以保证大数据量下的性能 方案三：基于缓存 + 消息队列 + 关系型数据库 选型: Redis + Kafka + Mysql/MongoDB/HBase 基本设计 基于Redis string型保存点赞数目，INCR原语保证点赞数目一致性 基于Redis bitmap设计是否点赞bloomfilter，取消点赞需要通过counting-filter实现 基于Kafka实现用户行为的快速持久化，每次点赞/取消点赞都保存为一条消息 通过消息消费，保存用户数据到关系型数据库 低频操作，如查询点赞历史等，通过查询关系型数据库实现 主要业务场景实现方案 点赞数 get O(1) 是否点赞 getbit O(1) （结果为真的情况下需要查询数据库，但整体概率较低） 点赞/取消点赞 incr/decr + setbit + 写入消息队列 O(1) 查询点赞历史，利用点赞主体索引进行查询，复杂度 O(log(N) *log(M)) 业务时序 功能模块 设计优势 兼具方案1和方案2的优点 消息队列弥补缓存持久性不足的缺点，同时减小了缓存与数据库文件系统间的写入效率差异 高可用性（并发响应）、高一致性，可以很好支持大部分ToC的业务场景 主要业务场景运算快速，可用性远胜于方案2 更低实现成本，对内存要求远低于方案1 整体扩展性更好 主要业务场景水平扩展性与方案1持平 低频业务场景可以选择写多读少的数据存储方案，水平扩展能力优于方案2 可以保存更多元数据，利于业务逻辑扩展 设计缺陷 实现较为复杂，对于多数业务场景来说存在过度设计的问题 业务高峰可能因为消息消费不及时带来部分数据延迟，如无法查询到点赞记录 部分实现代码 // 点赞 public boolean upvote(Upvote upvote) { // 增加主题计数 redisTemplate.opsForValue().increment(\"demo.community:upvote:count\" + upvote.getTopicId()); // 计算BloomFilter偏移量 int[] offsets = userHash(upvote.getUserId()); for (long offset : offsets) { redisTemplate.opsForValue().setBit(\"demo.community:upvote:user:filter\" + upvote.getTopicId(), offset, true); } // 异步发送消息 kafkaTemplate.send(\"demo-community-vote\", gson.toJson(upvote)); return true; } // 是否点赞 public boolean upVoted(Upvote upvote) { // 计算BloomFilter偏移量 int[] offsets = userHash(upvote.getUserId()); for (long offset : offsets) { if (!Boolean.TRUE.equals(redisTemplate.opsForValue().getBit(UPVOTE_USER_FILTER_PREFIX + upvote.getTopicId(), offset))) { // 不存在对应点赞数据，直接返回 return false; } } // 不能确定点赞记录是否存在，查询数据库 return upvoteMysqlDAO.findOne(Example.of(upvote)).isPresent(); } 性能测试 硬件情况： cpu intel i5 2.7GHz 4核8线程 memory 16G 系统和用户线程消耗 7G左右 受限于以下问题影响，测试结果仅供参考: 程序逻辑随机性不足，难以实际模拟真实生产数据场景 硬件限制，业务服务和数据库在同一个设备上，会形成资源竞争 实测过程中，发现用户服务对测试程序影响较大，同样的程序在不同时间执行也会存在差异 测试场景 主要测试以下四个场景： 1千万数据顺序写入数据库 1千万数据并发写入数据库 并发请求点赞数目1千万次 并发请求是否点赞1千万次 1千万数据顺序写入逻辑： @Test public void insert() { long topicId = 10_000_000L; long start = System.currentTimeMillis(); for (long userId = 1; userId 1千万数据并发写入逻辑： @Test public void insert() throws InterruptedException { ExecutorService executor = Executors.newFixedThreadPool(100); long start = System.currentTimeMillis(); AtomicInteger count = new AtomicInteger(); // 将用户分为100组，每组由1个线程顺序往10000个主题中写入数据 for (int taskId = 0; taskId { Upvote upvote = new Upvote(); upvote.setVotedAt(LocalDateTime.now()); for (long userId = startUserId; userId 1千万个请求并发查询点赞数 @Test public void testCount() throws Exception { ExecutorService executor = Executors.newFixedThreadPool(100); long start = System.currentTimeMillis(); AtomicInteger count = new AtomicInteger(); for (int i = 0; i { for (long topicId = 1; topicId 1千万个请求并发查询是否点赞 @Test public void testVoted() throws InterruptedException { ExecutorService executor = Executors.newFixedThreadPool(100); long start = System.currentTimeMillis(); AtomicInteger count = new AtomicInteger(); for (int taskId = 0; taskId { for (long userId = startUserId; userId 测试结果 所有场景测试结果(qps)如下表: 测试场景 方案一 方案二 方案三 顺序写入 7000 700 2200 并发写入 27700 2100 5600 点赞数 31600 1500 33800 是否点赞 28500 1400 13400 此处的qps指每秒完成的业务单元运算次数，不是指数据库层面的一个原子操作 Redis 测试情况 元素为8字节ID，socre为8字节时间戳，加上前驱后继指针共32字节，索引节点3个指针需要24字节 ZSet为跳表，检索1千万个元素需要索引节点数为 10_000_000 + 10_000_000/2 + 10_000_000/4 + ... + 1 ~= 20_000_000 预计1千万条数据的内存消耗 32B 1_000_000 + 24B 20_000_000 ~= 0.8GB 顺序写入：1千万个元素插入单个ZSet内，内存消耗1.16G，耗时1488S(单线程)，qps~=7000 并发写入：1千万个元素分布到1万个ZSet内，内存消耗1.06G，耗时361S(100线程)，qps~=27700 查询点赞数：100个线程并发查询1千万数据，耗时316S，qps~=31600 查询是否点赞：100个线程并发查询1千万数据，耗时351S，qps~=28500 Note: 由于Redis是基于内存的高速写入操作，实测过程中并发度到10左右qps即可达到程序瓶颈，并发度提升到100并不能提升整体吞吐量，反而会降低单个任务的处理时间 Mysql 测试情况 数据：主键ID-8字节，主题ID-8字节，用户ID-8字节，行为时间-8字节，每条数据32字节，索引24字节，总计56字节 顺序写入：1千万条数据单线程插入，执行了300万条数据，耗时4500秒，qps~=667 并发写入：1千万条数据100个线程并发插入，30分钟插入380万数据，qps~=2100 查询点赞数：查询60万数据，耗时391S，qps~=1500 查询是否点赞：查询50万数据，耗时366S，qps~=1400 Note: Mysql的写入效率远低于Redis，实测过程中需要达到50左右的并发度，才能逐渐触及瓶颈 通过Mysqladmin查看到，数据库qps约8000 mysqladmin -uroot status Uptime: 1517 Threads: 122 Questions: 12211865 Slow queries: 0 Opens: 246 Flush tables: 3 Open tables: 167 Queries per second avg: 8050.009 数据库的统计数据和实际运算结果呈现出来4倍差距，这个问题后续再分析。 Redis + Kafka + Mysql 测试情况 1千万个元素，按1%的误报率构建BloomFilter，需要三个数位保存，意味着要向Redis写入三次 1万个计数器，Redis内存基本没什么消耗 顺序写入：1千万条数据单线程写入，30分钟完成400万数据，qps~=2200 并发写入：1千万条数据并发写入，耗时1760S，qps~=5700 查询点赞数：100个线程并发查询1千万数据，耗时296S，qps~=33800 查询是否点赞：100个线程并发查询6百万数据，耗时446S，qps~=13400 Note: 对比方案一，本方案需要利用Redis存储BloomFilter，写入场景的频率增加了3倍，导致整体的吞吐量下降。从单机测试结果分析，写入瓶颈不在Kafka，而在于对布隆过滤器的多次位写入操作。如果减少布隆过滤器的写入次数，可以提升整体的吞吐效率。 通过Kafka-producer-perf-test查看写入性能，可以看到写入Kafka不是瓶颈 kafka-producer-perf-test --topic demo-community-vote --throughput -1 --num-records 100000 --record-size 1024 --producer-props bootstrap.servers=127.0.0.1:9092 100000 records sent, 52410.901468 records/sec (51.18 MB/sec), 291.51 ms avg latency, 667.00 ms max latency, 291 ms 50th, 369 ms 95th, 398 ms 99th, 428 ms 99.9th. 接口测试 使用 wrk 进行对三个常见业务场景进行性能测试： 随机写入点赞数据 查询点赞数量 查询是否点赞 由于硬件水平限制，并发超过2000时会触及Web服务器瓶颈，因此每个业务场景仅进行100并发和1000并发两次测试。 整体测试结果 场景 并发度 指标 方案一 方案二 方案三 写入点赞 100 p99 167ms 206ms 100ms qps 1800 1300 1600 1000 p99 254ms 3000ms 900ms qps 7100 700 1700 点赞数量 100 p99 47ms 716ms 55ms qps 4900 700 6000 1000 p99 182ms 2780ms 280ms qps 8500 500 6900 是否点赞 100 p99 36ms 500ms 70ms qps 5100 700 5200 1000 p99 488ms 2780ms 211ms qps 4200 600 7900 Redis 测试情况 随机写入点赞数据 Running 15s test @ http://127.0.0.1:8081/upvote/random 8 threads and 100 connections Thread Stats Avg Stdev Max +/- Stdev Latency 55.60ms 31.99ms 302.77ms 83.58% Req/Sec 227.21 100.30 475.00 55.26% Latency Distribution 50% 43.53ms 75% 65.46ms 90% 100.94ms 99% 167.34ms 27081 requests in 15.09s, 3.31MB read Requests/sec: 1794.27 Transfer/sec: 224.53KB Running 15s test @ http://127.0.0.1:8081/upvote/random 8 threads and 1000 connections Thread Stats Avg Stdev Max +/- Stdev Latency 135.43ms 34.15ms 326.33ms 79.71% Req/Sec 0.91k 290.23 1.89k 73.70% Latency Distribution 50% 131.31ms 75% 146.71ms 90% 171.76ms 99% 254.73ms 107072 requests in 15.09s, 13.09MB read Socket errors: connect 0, read 3491, write 24, timeout 0 Requests/sec: 7097.73 Transfer/sec: 0.87MB 随机查询点赞数量 Running 15s test @ http://127.0.0.1:8081/upvote/random/count 8 threads and 100 connections Thread Stats Avg Stdev Max +/- Stdev Latency 19.70ms 8.03ms 79.67ms 75.09% Req/Sec 617.23 186.98 1.16k 65.80% Latency Distribution 50% 18.89ms 75% 23.20ms 90% 28.27ms 99% 46.94ms 74139 requests in 15.10s, 9.06MB read Requests/sec: 4910.58 Transfer/sec: 614.66KB Running 15s test @ http://127.0.0.1:8081/upvote/random/count 8 threads and 1000 connections Thread Stats Avg Stdev Max +/- Stdev Latency 109.59ms 25.53ms 304.32ms 70.98% Req/Sec 1.09k 346.52 2.06k 77.26% Latency Distribution 50% 107.17ms 75% 120.24ms 90% 141.07ms 99% 182.09ms 128967 requests in 15.09s, 15.76MB read Socket errors: connect 0, read 6815, write 49, timeout 0 Requests/sec: 8544.67 Transfer/sec: 1.04MB 随机查询是否点赞 Running 15s test @ http://127.0.0.1:8081/upvote/random/voted 8 threads and 100 connections Thread Stats Avg Stdev Max +/- Stdev Latency 18.84ms 4.77ms 69.08ms 81.61% Req/Sec 641.78 102.37 0.91k 70.50% Latency Distribution 50% 17.91ms 75% 20.58ms 90% 24.04ms 99% 36.23ms 76797 requests in 15.04s, 9.46MB read Requests/sec: 5104.72 Transfer/sec: 644.00KB Running 15s test @ http://127.0.0.1:8081/upvote/random/voted 8 threads and 1000 connections Thread Stats Avg Stdev Max +/- Stdev Latency 240.45ms 69.55ms 588.15ms 75.02% Req/Sec 516.43 231.52 1.15k 66.13% Latency Distribution 50% 245.73ms 75% 275.92ms 90% 306.72ms 99% 488.76ms 60775 requests in 15.08s, 7.48MB read Socket errors: connect 0, read 3585, write 102, timeout 0 Requests/sec: 4029.91 Transfer/sec: 507.67KB Mysql 测试情况 单机并发在200左右还可以接受，到500并发时平均耗时直线上升 随机写入点赞数据 Running 15s test @ http://127.0.0.1:8081/upvote/random 8 threads and 100 connections Thread Stats Avg Stdev Max +/- Stdev Latency 74.73ms 39.44ms 358.83ms 75.32% Req/Sec 165.73 43.15 313.00 68.72% Latency Distribution 50% 65.42ms 75% 92.70ms 90% 127.60ms 99% 206.27ms 19753 requests in 15.10s, 2.41MB read Requests/sec: 1308.35 Transfer/sec: 163.76KB Running 15s test @ http://127.0.0.1:8081/upvote/random 8 threads and 1000 connections Thread Stats Avg Stdev Max +/- Stdev Latency 1.28s 623.37ms 3.52s 76.48% Req/Sec 96.99 56.02 290.00 64.44% Latency Distribution 50% 1.09s 75% 1.57s 90% 2.22s 99% 3.06s 11021 requests in 15.10s, 1.35MB read Socket errors: connect 0, read 4464, write 14, timeout 0 Requests/sec: 729.82 Transfer/sec: 91.24KB 随机查询点赞数量 Running 15s test @ http://127.0.0.1:8081/upvote/random/count 8 threads and 100 connections Thread Stats Avg Stdev Max +/- Stdev Latency 159.69ms 164.80ms 1.06s 85.51% Req/Sec 93.75 45.13 290.00 72.45% Latency Distribution 50% 125.30ms 75% 244.04ms 90% 377.00ms 99% 716.69ms 11202 requests in 15.09s, 1.37MB read Requests/sec: 742.51 Transfer/sec: 92.69KB Running 15s test @ http://127.0.0.1:8081/upvote/random/count 8 threads and 1000 connections Thread Stats Avg Stdev Max +/- Stdev Latency 1.72s 560.49ms 3.31s 72.10% Req/Sec 70.20 37.27 280.00 64.61% Latency Distribution 50% 1.75s 75% 2.10s 90% 2.46s 99% 2.78s 7962 requests in 15.08s, 0.97MB read Socket errors: connect 0, read 5757, write 71, timeout 0 Requests/sec: 528.03 Transfer/sec: 65.84KB 随机查询是否点赞 Running 15s test @ http://127.0.0.1:8081/upvote/random/voted 8 threads and 100 connections Thread Stats Avg Stdev Max +/- Stdev Latency 143.77ms 123.50ms 960.63ms 74.31% Req/Sec 94.14 44.22 272.00 66.52% Latency Distribution 50% 114.05ms 75% 212.47ms 90% 307.71ms 99% 545.08ms 11113 requests in 15.10s, 1.37MB read Requests/sec: 735.87 Transfer/sec: 92.81KB Running 15s test @ http://127.0.0.1:8081/upvote/random/voted 8 threads and 1000 connections Thread Stats Avg Stdev Max +/- Stdev Latency 1.60s 492.57ms 3.11s 78.52% Req/Sec 74.13 42.23 352.00 66.27% Latency Distribution 50% 1.57s 75% 1.86s 90% 2.20s 99% 2.79s 8320 requests in 15.09s, 1.02MB read Socket errors: connect 0, read 4051, write 278, timeout 0 Requests/sec: 551.44 Transfer/sec: 69.46KB Redis + Kafka + Mysql 测试情况 随机写入点赞数据 Running 15s test @ http://127.0.0.1:8081/upvote/random 8 threads and 100 connections Thread Stats Avg Stdev Max +/- Stdev Latency 59.28ms 12.85ms 115.39ms 69.38% Req/Sec 202.63 43.91 393.00 73.50% Latency Distribution 50% 58.69ms 75% 66.57ms 90% 75.54ms 99% 100.70ms 24317 requests in 15.08s, 2.97MB read Requests/sec: 1612.34 Transfer/sec: 201.79KB Running 15s test @ http://127.0.0.1:8081/upvote/random 8 threads and 1000 connections Thread Stats Avg Stdev Max +/- Stdev Latency 536.15ms 146.29ms 1.02s 70.19% Req/Sec 235.21 207.01 1.02k 70.95% Latency Distribution 50% 515.93ms 75% 634.72ms 90% 726.52ms 99% 923.41ms 25059 requests in 15.09s, 3.06MB read Socket errors: connect 0, read 6929, write 108, timeout 0 Requests/sec: 1660.10 Transfer/sec: 207.53KB 随机查询点赞数量 Running 15s test @ http://127.0.0.1:8081/upvote/random/count 8 threads and 100 connections Thread Stats Avg Stdev Max +/- Stdev Latency 16.42ms 8.79ms 154.03ms 88.85% Req/Sec 761.49 211.02 1.61k 77.67% Latency Distribution 50% 14.68ms 75% 17.33ms 90% 22.60ms 99% 54.78ms 91281 requests in 15.05s, 10.91MB read Requests/sec: 6063.49 Transfer/sec: 741.87KB Running 15s test @ http://127.0.0.1:8081/upvote/random/count 8 threads and 1000 connections Thread Stats Avg Stdev Max +/- Stdev Latency 131.90ms 40.43ms 531.49ms 76.71% Req/Sec 0.91k 379.89 2.01k 77.34% Latency Distribution 50% 121.78ms 75% 142.15ms 90% 186.37ms 99% 282.30ms 103664 requests in 15.09s, 12.39MB read Socket errors: connect 0, read 6273, write 96, timeout 0 Requests/sec: 6871.93 Transfer/sec: 840.78KB 随机查询是否点赞 Running 15s test @ http://127.0.0.1:8081/upvote/random/voted 8 threads and 100 connections Thread Stats Avg Stdev Max +/- Stdev Latency 20.76ms 46.51ms 2.15s 98.79% Req/Sec 655.35 243.15 1.55k 75.25% Latency Distribution 50% 16.47ms 75% 20.96ms 90% 31.04ms 99% 69.94ms 78604 requests in 15.09s, 9.68MB read Requests/sec: 5207.97 Transfer/sec: 657.04KB Running 15s test @ http://127.0.0.1:8081/upvote/random/voted 8 threads and 1000 connections Thread Stats Avg Stdev Max +/- Stdev Latency 113.65ms 28.75ms 386.92ms 73.48% Req/Sec 1.01k 382.66 2.03k 76.39% Latency Distribution 50% 109.56ms 75% 122.12ms 90% 148.83ms 99% 211.10ms 119410 requests in 15.10s, 14.71MB read Socket errors: connect 0, read 7855, write 85, timeout 0 Requests/sec: 7909.80 Transfer/sec: 0.97MB 总结 基于上述测试结果，总结一下各个方案的优缺点： 方案 优点 缺点 备注 优先队列 高可用、高一致、易扩展、易实现 成本要求较高 适合数据量不高，需求不明确的场景 关系型数据库 高一致、强持久、低成本、易实现 并发度低，难水平扩展 适合低并发场景 缓存+消息队列+关系型数据库 高可用、强一致、强持久、低成本、易扩展 实现复杂，存在过度设计风险 适合高并发、数据量大、需求明确的场景 基于上述优缺点，个人建议： 大部分业务场景，在千万级数据量级别时，可以直接选择方案一，因为实现简单，且可以向任意方案扩展 基础数据量较大，且增速较快，可以选择方案三，因为扩展性和一致性都更强。通常数据量的增长与并发度呈正相关，大数据量意味着高并发 业务系统简单，用户量在十万级别时，可以选择方案二，基本不会出现性能瓶颈。但这种情况，方案一也大概率可以覆盖 实践中，选择方案一可以满足大部分业务场景。 点赞计数是一个拥有热点数据的场景，可以通过冷数据入库的方式来节约内存成本。比如三个月以前的数据可以选择从Redis中清除，持久化到数据库。在查询过程中，可以通过一个BloomFilter存储对应主体的数据是否已经持久化到关系型数据库。通过这个结果来判断访问内存还是访问关系型数据库。 实际业务中，不同场景可以有不同优化方案。比如用户对看到的点赞数、是否点赞等数据的一致性要求并不是那么高，可以通过客户端缓存等方式降低对服务端一致性的要求和访问压力。具体情况具体分析，本文的设计方案只针对服务端进行设计。 后记 技术方案设计过程中，除了进行经验评估，往往还需要在实践中来验证自己的想法。 在这次测试过程中，遇到过许多与设计预期不符合的情况，如： Redis内存消耗大于方案设计时的预期，原因是没考虑到跳表的索引节点开销 BloomFilter设计不合理，导致Redis成为写入瓶颈，原因是参数不合理，导致需要数十次Redis访问 受连接池配置、Web服务器配置影响，测试结果远低于预期等 这些问题都是在实践过程中遇到后，逐步分析，一个一个解决的。这些问题再次印证那一句名言： 实践是检验真理的唯一标准。 var gitalk = new Gitalk({ clientID: '6c5979cef62fdd9b4854', clientSecret: 'af796559c2892e1ebbf10480d8c2fc2d0bb4af24', repo: 'chainj.github.io', owner: 'ChainJ', admin: ['ChainJ'], id: location.pathname, distractionFreeMode: false }) gitalk.render('gitalk-container') © Cheng all right reserved，powered by GitbookModified At: 2021-12-10 14:21:42 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"}}